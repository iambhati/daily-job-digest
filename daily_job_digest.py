{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCew03wVSP/wffoTn05aMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iambhati/daily-job-digest/blob/main/daily_job_digest.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsJEGQOK1zXd"
      },
      "outputs": [],
      "source": [
        "pip install requests beautifulsoup4 schedule\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG_MODE = True  # Keep this True initially"
      ],
      "metadata": {
        "id": "b0BZ2Nz7Yz3q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install webdriver-manager"
      ],
      "metadata": {
        "id": "JC5l1pksYxQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium webdriver-manager requests beautifulsoup4"
      ],
      "metadata": {
        "id": "taToAUSSYSJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Enhanced Daily Job Digest Script with Better Location Filtering and Remote Jobs\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "import time\n",
        "import random\n",
        "from urllib.parse import quote_plus\n",
        "import re\n",
        "\n",
        "# ---------------- USER SETTINGS ----------------\n",
        "KEYWORDS = [\n",
        "    \"Entry level Data Analyst\",\n",
        "    \"Entry level Business Analyst\",\n",
        "    \"Junior Analyst\",\n",
        "    \"Fresher Analyst\",\n",
        "    \"Associate Data Analyst\",\n",
        "    \"Associate Business Analyst\",\n",
        "    \"Trainee Analyst\",\n",
        "    \"Graduate Analyst\",\n",
        "    \"Junior Data Scientist\",\n",
        "    \"Business Intelligence Analyst\"\n",
        "]\n",
        "\n",
        "# Target locations - expanded list\n",
        "TARGET_LOCATIONS = [\"Gurgaon\", \"Noida\", \"Jaipur\", \"Delhi\", \"NCR\", \"Gurugram\", \"New Delhi\"]\n",
        "INCLUDE_REMOTE = True\n",
        "\n",
        "# Remote work keywords - comprehensive list\n",
        "REMOTE_KEYWORDS = [\n",
        "    \"remote\", \"work from home\", \"wfh\", \"hybrid\", \"anywhere\", \"telecommute\",\n",
        "    \"distributed\", \"virtual\", \"home office\", \"flexible location\", \"remote work\",\n",
        "    \"work remotely\", \"home based\", \"location independent\"\n",
        "]\n",
        "\n",
        "RESULTS_PER_SITE = 10  # Increased from 5\n",
        "SENDER_EMAIL = \"learnxaiml@gmail.com\"\n",
        "APP_PASSWORD = \"jkfr lftg gjta sadq\"\n",
        "RECEIVER_EMAIL = \"learnxaiml@gmail.com\"\n",
        "\n",
        "# ---------------- ENHANCED HELPERS ----------------\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "def is_remote_job(location: str, title: str = \"\", description: str = \"\") -> bool:\n",
        "    \"\"\"Enhanced remote job detection\"\"\"\n",
        "    if not location and not title and not description:\n",
        "        return False\n",
        "\n",
        "    text_to_check = f\"{location} {title} {description}\".lower()\n",
        "    return any(keyword in text_to_check for keyword in REMOTE_KEYWORDS)\n",
        "\n",
        "def location_allowed(location: str, title: str = \"\", description: str = \"\") -> bool:\n",
        "    \"\"\"Enhanced location filtering with better remote detection\"\"\"\n",
        "    if not location:\n",
        "        return False\n",
        "\n",
        "    loc_lower = location.lower()\n",
        "\n",
        "    # Check for remote work\n",
        "    if INCLUDE_REMOTE and is_remote_job(location, title, description):\n",
        "        return True\n",
        "\n",
        "    # Check for target cities\n",
        "    for city in TARGET_LOCATIONS:\n",
        "        if city.lower() in loc_lower:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and normalize text\"\"\"\n",
        "    if not text:\n",
        "        return \"N/A\"\n",
        "    return re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "def random_delay():\n",
        "    \"\"\"Add random delay to avoid being blocked\"\"\"\n",
        "    time.sleep(random.uniform(1, 3))\n",
        "\n",
        "# ---------------- ENHANCED SCRAPERS ----------------\n",
        "def search_naukri(keyword):\n",
        "    \"\"\"Enhanced Naukri scraper with multiple selectors\"\"\"\n",
        "    jobs = []\n",
        "    search_term = keyword.replace(' ', '-').lower()\n",
        "    url = f\"https://www.naukri.com/{search_term}-jobs\"\n",
        "\n",
        "    try:\n",
        "        random_delay()\n",
        "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        # Try multiple selectors for job cards\n",
        "        selectors = [\n",
        "            \"article.jobTuple\",\n",
        "            \"div.jobTuple\",\n",
        "            \"div[class*='jobTuple']\",\n",
        "            \"div.srp-jobtuple-wrapper\",\n",
        "            \"div.job-tuple\"\n",
        "        ]\n",
        "\n",
        "        cards = []\n",
        "        for selector in selectors:\n",
        "            cards = soup.select(selector)\n",
        "            if cards:\n",
        "                break\n",
        "\n",
        "        cards = cards[:RESULTS_PER_SITE]\n",
        "        print(f\"[DEBUG] Found {len(cards)} Naukri cards for '{keyword}'\")\n",
        "\n",
        "        for card in cards:\n",
        "            # Try multiple selectors for each field\n",
        "            title_selectors = [\"a.title\", \"h2 a\", \"h3 a\", \"a[class*='title']\", \".jobTupleHeader a\"]\n",
        "            company_selectors = [\"a.subTitle\", \".companyInfo a\", \"a[class*='subTitle']\", \".company a\"]\n",
        "            location_selectors = [\"li.location\", \".locWdth\", \".location\", \"[class*='location']\"]\n",
        "\n",
        "            title = company = location = link = None\n",
        "\n",
        "            # Extract title and link\n",
        "            for sel in title_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem:\n",
        "                    title = clean_text(elem.get_text())\n",
        "                    link = elem.get('href', '#')\n",
        "                    if not link.startswith('http'):\n",
        "                        link = f\"https://www.naukri.com{link}\"\n",
        "                    break\n",
        "\n",
        "            # Extract company\n",
        "            for sel in company_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem:\n",
        "                    company = clean_text(elem.get_text())\n",
        "                    break\n",
        "\n",
        "            # Extract location\n",
        "            for sel in location_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem:\n",
        "                    location = clean_text(elem.get_text())\n",
        "                    break\n",
        "\n",
        "            if title and title != \"N/A\" and location_allowed(location, title):\n",
        "                jobs.append((title, company or \"N/A\", location or \"N/A\", link or \"#\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Naukri fetch failed for '{keyword}': {e}\")\n",
        "\n",
        "    return jobs\n",
        "\n",
        "def search_linkedin(keyword):\n",
        "    \"\"\"Enhanced LinkedIn scraper\"\"\"\n",
        "    jobs = []\n",
        "    search_term = quote_plus(keyword)\n",
        "    url = f\"https://www.linkedin.com/jobs/search?keywords={search_term}&location=India\"\n",
        "\n",
        "    try:\n",
        "        random_delay()\n",
        "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        # Try multiple selectors\n",
        "        selectors = [\n",
        "            \"div.base-card\",\n",
        "            \"li.result-card\",\n",
        "            \"div[class*='job-search-card']\",\n",
        "            \"div.job-card-container\"\n",
        "        ]\n",
        "\n",
        "        cards = []\n",
        "        for selector in selectors:\n",
        "            cards = soup.select(selector)\n",
        "            if cards:\n",
        "                break\n",
        "\n",
        "        cards = cards[:RESULTS_PER_SITE]\n",
        "        print(f\"[DEBUG] Found {len(cards)} LinkedIn cards for '{keyword}'\")\n",
        "\n",
        "        for card in cards:\n",
        "            # Multiple selectors for each field\n",
        "            title_selectors = [\"h3\", \"h3 a\", \".job-card-list__title\", \"a .sr-only\"]\n",
        "            company_selectors = [\"h4\", \"h4 a\", \".job-card-container__company-name\", \".job-result-card__company-name\"]\n",
        "            location_selectors = [\".job-search-card__location\", \".job-result-card__location\", \".job-card-container__metadata-item\"]\n",
        "            link_selectors = [\"a\", \"h3 a\"]\n",
        "\n",
        "            title = company = location = link = None\n",
        "\n",
        "            # Extract title\n",
        "            for sel in title_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem:\n",
        "                    title = clean_text(elem.get_text())\n",
        "                    break\n",
        "\n",
        "            # Extract company\n",
        "            for sel in company_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem:\n",
        "                    company = clean_text(elem.get_text())\n",
        "                    break\n",
        "\n",
        "            # Extract location\n",
        "            for sel in location_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem:\n",
        "                    location = clean_text(elem.get_text())\n",
        "                    break\n",
        "\n",
        "            # Extract link\n",
        "            for sel in link_selectors:\n",
        "                elem = card.select_one(sel)\n",
        "                if elem and elem.get('href'):\n",
        "                    link = elem['href']\n",
        "                    if not link.startswith('http'):\n",
        "                        link = f\"https://www.linkedin.com{link}\"\n",
        "                    break\n",
        "\n",
        "            if title and title != \"N/A\" and location_allowed(location, title):\n",
        "                jobs.append((title, company or \"N/A\", location or \"N/A\", link or \"#\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] LinkedIn fetch failed for '{keyword}': {e}\")\n",
        "\n",
        "    return jobs\n",
        "\n",
        "def search_indeed(keyword):\n",
        "    \"\"\"New Indeed scraper\"\"\"\n",
        "    jobs = []\n",
        "    search_term = quote_plus(keyword)\n",
        "    url = f\"https://in.indeed.com/jobs?q={search_term}&l=India\"\n",
        "\n",
        "    try:\n",
        "        random_delay()\n",
        "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        cards = soup.select(\"div.job_seen_beacon, div[data-jk], td.resultContent\")[:RESULTS_PER_SITE]\n",
        "        print(f\"[DEBUG] Found {len(cards)} Indeed cards for '{keyword}'\")\n",
        "\n",
        "        for card in cards:\n",
        "            title_elem = card.select_one(\"h2 a span, h2 span a, a[data-testid='job-title']\")\n",
        "            company_elem = card.select_one(\"span.companyName, a .companyName, span[data-testid='company-name']\")\n",
        "            location_elem = card.select_one(\"div.companyLocation, div[data-testid='job-location']\")\n",
        "            link_elem = card.select_one(\"h2 a, a[data-testid='job-title']\")\n",
        "\n",
        "            title = clean_text(title_elem.get_text()) if title_elem else \"N/A\"\n",
        "            company = clean_text(company_elem.get_text()) if company_elem else \"N/A\"\n",
        "            location = clean_text(location_elem.get_text()) if location_elem else \"N/A\"\n",
        "            link = link_elem.get('href', '#') if link_elem else \"#\"\n",
        "\n",
        "            if not link.startswith('http') and link != \"#\":\n",
        "                link = f\"https://in.indeed.com{link}\"\n",
        "\n",
        "            if title != \"N/A\" and location_allowed(location, title):\n",
        "                jobs.append((title, company, location, link))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Indeed fetch failed for '{keyword}': {e}\")\n",
        "\n",
        "    return jobs\n",
        "\n",
        "def search_glassdoor(keyword):\n",
        "    \"\"\"New Glassdoor scraper\"\"\"\n",
        "    jobs = []\n",
        "    search_term = quote_plus(keyword)\n",
        "    url = f\"https://www.glassdoor.co.in/Job/jobs.htm?sc.keyword={search_term}&locT=N&locId=115\"\n",
        "\n",
        "    try:\n",
        "        random_delay()\n",
        "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        cards = soup.select(\"li[data-test='jobListing'], div.react-job-listing\")[:RESULTS_PER_SITE]\n",
        "        print(f\"[DEBUG] Found {len(cards)} Glassdoor cards for '{keyword}'\")\n",
        "\n",
        "        for card in cards:\n",
        "            title_elem = card.select_one(\"a[data-test='job-link'], .jobLink\")\n",
        "            company_elem = card.select_one(\"[data-test='employer-name'], .jobEmpolyerName\")\n",
        "            location_elem = card.select_one(\"[data-test='job-location'], .jobLocation\")\n",
        "\n",
        "            title = clean_text(title_elem.get_text()) if title_elem else \"N/A\"\n",
        "            company = clean_text(company_elem.get_text()) if company_elem else \"N/A\"\n",
        "            location = clean_text(location_elem.get_text()) if location_elem else \"N/A\"\n",
        "            link = title_elem.get('href', '#') if title_elem else \"#\"\n",
        "\n",
        "            if not link.startswith('http') and link != \"#\":\n",
        "                link = f\"https://www.glassdoor.co.in{link}\"\n",
        "\n",
        "            if title != \"N/A\" and location_allowed(location, title):\n",
        "                jobs.append((title, company, location, link))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Glassdoor fetch failed for '{keyword}': {e}\")\n",
        "\n",
        "    return jobs\n",
        "\n",
        "# ---------------- ENHANCED EMAIL ----------------\n",
        "def send_email(jobs):\n",
        "    \"\"\"Enhanced email with better formatting\"\"\"\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    subject = f\"🎯 Daily Analyst Job Digest – {now} ({len(jobs)} opportunities)\"\n",
        "\n",
        "    # Separate remote and location-based jobs\n",
        "    remote_jobs = []\n",
        "    location_jobs = []\n",
        "\n",
        "    for job in jobs:\n",
        "        title, company, location, link = job\n",
        "        if is_remote_job(location, title):\n",
        "            remote_jobs.append(job)\n",
        "        else:\n",
        "            location_jobs.append(job)\n",
        "\n",
        "    body = f\"\"\"\n",
        "    <html>\n",
        "    <body style=\"font-family: Arial, sans-serif; line-height: 1.6; color: #333;\">\n",
        "        <h2 style=\"color: #2c5aa0;\">🎯 Daily Analyst Job Opportunities</h2>\n",
        "        <p>Hello Sam,</p>\n",
        "        <p>Here are today's top entry-level analyst job opportunities ({len(jobs)} total jobs found):</p>\n",
        "    \"\"\"\n",
        "\n",
        "    if remote_jobs:\n",
        "        body += f\"\"\"\n",
        "        <h3 style=\"color: #28a745;\">🏠 Remote/WFH Opportunities ({len(remote_jobs)} jobs)</h3>\n",
        "        <div style=\"margin-left: 20px;\">\n",
        "        \"\"\"\n",
        "        for job in remote_jobs:\n",
        "            title, company, location, link = job\n",
        "            body += f\"\"\"\n",
        "            <div style=\"margin-bottom: 15px; padding: 10px; border-left: 3px solid #28a745; background-color: #f8f9fa;\">\n",
        "                <strong style=\"color: #28a745;\">{title}</strong><br>\n",
        "                <span style=\"color: #666;\">{company} – {location}</span><br>\n",
        "                <a href=\"{link}\" style=\"color: #2c5aa0; text-decoration: none;\">Apply Here →</a>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        body += \"</div>\"\n",
        "\n",
        "    if location_jobs:\n",
        "        body += f\"\"\"\n",
        "        <h3 style=\"color: #dc3545;\">📍 Location-Based Opportunities ({len(location_jobs)} jobs)</h3>\n",
        "        <div style=\"margin-left: 20px;\">\n",
        "        \"\"\"\n",
        "        for job in location_jobs:\n",
        "            title, company, location, link = job\n",
        "            body += f\"\"\"\n",
        "            <div style=\"margin-bottom: 15px; padding: 10px; border-left: 3px solid #dc3545; background-color: #f8f9fa;\">\n",
        "                <strong style=\"color: #dc3545;\">{title}</strong><br>\n",
        "                <span style=\"color: #666;\">{company} – {location}</span><br>\n",
        "                <a href=\"{link}\" style=\"color: #2c5aa0; text-decoration: none;\">Apply Here →</a>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        body += \"</div>\"\n",
        "\n",
        "    body += \"\"\"\n",
        "        <hr style=\"margin: 30px 0;\">\n",
        "        <p style=\"color: #666; font-size: 14px;\">\n",
        "            💡 <strong>Tips:</strong><br>\n",
        "            • Apply early for better chances<br>\n",
        "            • Customize your resume for each role<br>\n",
        "            • Research the company before applying<br>\n",
        "            • Follow up after 1-2 weeks if no response\n",
        "        </p>\n",
        "        <p>Good luck with your applications! 🚀</p>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    msg = MIMEMultipart()\n",
        "    msg[\"From\"] = SENDER_EMAIL\n",
        "    msg[\"To\"] = RECEIVER_EMAIL\n",
        "    msg[\"Subject\"] = subject\n",
        "    msg.attach(MIMEText(body, \"html\"))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
        "        server.starttls()\n",
        "        server.login(SENDER_EMAIL, APP_PASSWORD)\n",
        "        server.sendmail(SENDER_EMAIL, RECEIVER_EMAIL, msg.as_string())\n",
        "        server.quit()\n",
        "        print(f\"[INFO] ✅ Email sent successfully to {RECEIVER_EMAIL}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] ❌ Failed to send email: {e}\")\n",
        "\n",
        "# ---------------- ENHANCED MAIN ----------------\n",
        "def fetch_all_and_send():\n",
        "    \"\"\"Enhanced main function with multiple job sites\"\"\"\n",
        "    print(f\"[INFO] 🔍 Starting job search at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"[INFO] 📍 Target locations: {', '.join(TARGET_LOCATIONS)}\")\n",
        "    print(f\"[INFO] 🏠 Include remote: {INCLUDE_REMOTE}\")\n",
        "\n",
        "    all_jobs = []\n",
        "\n",
        "    # Search functions with their names\n",
        "    search_functions = [\n",
        "        (\"Naukri\", search_naukri),\n",
        "        (\"LinkedIn\", search_linkedin),\n",
        "        (\"Indeed\", search_indeed),\n",
        "        (\"Glassdoor\", search_glassdoor)\n",
        "    ]\n",
        "\n",
        "    for kw in KEYWORDS:\n",
        "        print(f\"\\n[INFO] 🔎 Searching for: '{kw}'\")\n",
        "        for site_name, search_func in search_functions:\n",
        "            try:\n",
        "                jobs = search_func(kw)\n",
        "                all_jobs.extend(jobs)\n",
        "                print(f\"[INFO] {site_name}: Found {len(jobs)} jobs\")\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] {site_name}: Search failed - {e}\")\n",
        "\n",
        "    print(f\"\\n[INFO] 📊 Total jobs before deduplication: {len(all_jobs)}\")\n",
        "\n",
        "    # Enhanced deduplication - normalize titles for better matching\n",
        "    def normalize_title(title):\n",
        "        return re.sub(r'[^\\w\\s]', '', title.lower()).strip()\n",
        "\n",
        "    seen = set()\n",
        "    unique_jobs = []\n",
        "    for job in all_jobs:\n",
        "        title, company, location, link = job\n",
        "        # Create key with normalized title and company\n",
        "        key = (normalize_title(title), company.lower().strip())\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            unique_jobs.append(job)\n",
        "\n",
        "    print(f\"[INFO] 📊 Unique jobs after deduplication: {len(unique_jobs)}\")\n",
        "\n",
        "    if unique_jobs:\n",
        "        # Sort jobs - remote jobs first, then by company name\n",
        "        unique_jobs.sort(key=lambda x: (not is_remote_job(x[2], x[0]), x[1].lower()))\n",
        "        send_email(unique_jobs)\n",
        "\n",
        "        # Print summary\n",
        "        remote_count = sum(1 for job in unique_jobs if is_remote_job(job[2], job[0]))\n",
        "        location_count = len(unique_jobs) - remote_count\n",
        "        print(f\"[INFO] 📧 Email sent with {len(unique_jobs)} jobs ({remote_count} remote, {location_count} location-based)\")\n",
        "    else:\n",
        "        print(\"[INFO] ❌ No matching jobs found today.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fetch_all_and_send()"
      ],
      "metadata": {
        "id": "dkTYiMC62EH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPtlEgEY4QLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}